---
title: 万维钢AI专题学习笔记
date: 2023-03-13 12:59 
category: "日志"
tags: ["阅读笔记"]
---

> 今日冥想：15分钟
> 影子跟读：10分钟
> 单词学习：impeccable，无可挑剔的；deceive，欺骗；consent，同意
> 今日运动：引体向上6个

机器学习有三个大类：监督学习、无监督学习和强化学习。

- 监督学习：像老师对学生的教学，对错有标准答案，但可以不讲原理。
- 无监督学习：像一个学者，自己调研了大量内容，看多了就学会了。
- 强化学习：像训练运动员，哪个动作错了立即给你纠正。


监督学习是指从带有标签的训练数据中学习出一个模型，以便对未知数据进行预测。它的目标是最小化预测结果与真实标签之间的差距，常用于分类、回归等任务。比如图像识别、翻译等。

无监督学习是指从未标注的数据中学习出数据的内在结构和特征，以便更好地理解和处理数据。它的目标是发现数据中的潜在结构和规律，常用于聚类、降维等任务。比如淘宝、抖音的推荐等。

强化学习是指智能体通过与环境的交互，从环境反馈中学习出一种行为策略，以最大化累积奖励。它的目标是学习出一种最优策略，常用于游戏、机器人控制等任务。

ChatGPT用了什么技术呢？

Chat代表聊天，GPT是它的核心技术，是一种基于Transformer架构的、经过预训练的、生成性的模型。

Transformer 模型的训练过程是无监督的，但是在应用时通常需要进行监督学习的微调，例如在机器翻译任务中，需要使用有标注的平行语料来微调模型，以提高翻译的准确性和流畅度。

ChatGPT的技术原理（From ChatGPT）：

首先，ChatGPT使用无监督学习的方式对海量语料进行预训练，学习出一个通用的自然语言模型。这个模型可以理解自然语言的语法和语义，能够自动提取文本中的特征和语义信息。

接着，ChatGPT使用监督学习的方式对聊天数据进行微调，以适应特定的聊天场景和用户需求。在微调阶段，ChatGPT将聊天数据作为带标签的训练数据，通过最小化模型输出与真实回复之间的差距来优化模型参数。这样，ChatGPT可以根据用户输入的文本生成符合语境和语法的自然语言回复。

最后，ChatGPT还应用了强化学习的方法来优化生成的回复。通过与用户的交互，ChatGPT可以根据用户反馈的奖励信号来调整生成回复的策略，以提高回复的质量和准确性。

据说OpenAI内部的人也搞不清楚为什么ChatGPT效果这么好，看起来那么有智能。

一个解释是：“涌现”：当一个复杂系统达到一定程度时，会自发产生超越系统个体简单叠加的自组织现象。

- 单个蚂蚁很笨，但蚁群非常聪明。
- 每个消费者都是自由的，但整个市场有序。
- 每个神经元都很简单，但大脑产生了意识。

是“涌现”让AI获得了推理、类比、少样本学习等等思考能力。

ChatGPT这么强，为什么现在还没发挥出生产力效能？

《权力与预测》指出，通用技术需要经过三个阶段才能真正发挥生产力效能。
- 第一阶段是「点解决方案」，只是简单的输入端替换。
- 第二阶段是「应用解决方案」，需要将生产装置也进行更换。
- 第三阶段是「系统解决方案」，需要对整个生产方式和组织方式进行系统性的变革。
- 目前对AI的应用还处在前两个阶段，还没有达到系统解决方案阶段，因此AI还没有发挥最大的作用。

比如电力发明后，灯泡只是比蜡烛方便一点，电动力比蒸汽动力便宜点，有替换意愿，但还不够刚需。这只是“点解决方案”。

后来到了工厂意识到，蒸汽轴连着所有蒸汽机，蒸汽一开所有机器都要开。改用电力能自由控制机器是否运转，更省钱。但这个这是一笔不小的投入，也需要比较长的时间。对生产装置的更换就是“应用解决方案”阶段。

到最后，用上了电力，随处安装插头，机器可以放在工厂任意位置，这样就能充分利用空间，使得“生产流水线”成为可能，这时就不是局部改进，而且整个生产方式和组织方式都得到系统性的变革。

目前为止，AI应用还处在解决方案和少量的应用解决方案阶段，还没达到系统解决方案阶段，未来可期待。

ChatGPT对学习影响？

在没有正规教材和课堂时代，学习是以师生问答的形式进行的。ChatGPT是一种对话式的学习，效率高。
大脑的存储能力是海量的，但输入输出和逻辑运算的速度太慢。AI适合作为人的第二大脑，通过AI对话快速学习，获得反馈。


生成式AI的版权问题

- 美国尚未有法律规定是否可以使用受版权保护的语料训练语言模型，也没有判例。
-  微软和它旗下Github网站被指控Copilot侵犯了一些开源代码的版权，艺术家对AI图片生成网站发起诉讼，新闻机构起诉OpenAI。

ChatGPT的语料截至到2021年，如何处理新知识？

训练大型语言模型需要消耗大量算力和语料，非常的昂贵。GPT-3.5是去年炼成的，语料截至2021年。
让GPT处理新知识有两个办法：fine-tune（微调）和小样本临时学习。

OpenAI声明的三个问题

- 如何管理AI系统？
- 如何公平分配AI系统产生的利益？
- 如何公平分享使用AI系统的权利？

AI时代需要新的哲学和道德观念

- AI的发展会带来历史上大规模的社会转折点。
- 过去的转折点有的带来了好处有的带来了动乱，我们需要思考如何应对AI带来的变化。
- 现在的“元问题”是我们需要具备AI时代的哲学，需要自己的笛卡尔和康德来解释这一切。


和朋友的开脑洞讨论
- 如果AI能给出靠谱的答案和解决方案，以后知识获取都从AI来，AI就是最大的宗教。服务器变成了人类共有的神。
- AI的判断总是比人类正确，一定会从相信AI变成信仰AI。AI给出的答案，就是命运的安排。AI由少数精英控制，从而控制大部分人的思想。
- Web3和AI的观念冲突很大，如果能结合更有想象空间。比如个人数据上链且加密，自己选择是否接受被AI使用，用数据要给用户付费；Prompt的发明者，传播者都应该有收益。
- Peter Thiel: "Crypto is libertarian, AI is communist."  一个是自由主义，一个是共产主义。
